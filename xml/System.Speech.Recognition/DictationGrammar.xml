<Type Name="DictationGrammar" FullName="System.Speech.Recognition.DictationGrammar">
  <Metadata><Meta Name="ms.openlocfilehash" Value="18a457ab8c4b088fb91ffc48e4b48c4dc26c4a89" /><Meta Name="ms.sourcegitcommit" Value="397961a0164281b579f68064c3bb66c071f374d9" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="zh-CN" /><Meta Name="ms.lasthandoff" Value="07/14/2020" /><Meta Name="ms.locfileid" Value="69231370" /></Metadata><TypeSignature Language="C#" Value="public class DictationGrammar : System.Speech.Recognition.Grammar" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit DictationGrammar extends System.Speech.Recognition.Grammar" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.DictationGrammar" />
  <TypeSignature Language="VB.NET" Value="Public Class DictationGrammar&#xA;Inherits Grammar" />
  <TypeSignature Language="C++ CLI" Value="public ref class DictationGrammar : System::Speech::Recognition::Grammar" />
  <TypeSignature Language="F#" Value="type DictationGrammar = class&#xA;    inherit Grammar" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Speech.Recognition.Grammar</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>表示用于自由文本口述的语音识别语法。</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 此类为应用程序提供了一个预定义的语言模型，该模型可以处理文本中的用户输入。 此类支持默认对象和自定义 <xref:System.Speech.Recognition.DictationGrammar> 对象。 有关选择听写语法的信息，请参阅 <xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29> 构造函数。  
  
 默认情况下， <xref:System.Speech.Recognition.DictationGrammar> 语言模型为上下文可用。 它不会使用特定的单词或字顺序来识别和解释音频输入。 若要将上下文添加到听写语法，请使用 <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> 方法。  
  
> [!NOTE]
>  <xref:System.Speech.Recognition.DictationGrammar>对象不支持 <xref:System.Speech.Recognition.Grammar.Priority%2A> 属性。 <xref:System.Speech.Recognition.DictationGrammar><xref:System.NotSupportedException>如果 <xref:System.Speech.Recognition.Grammar.Priority%2A> 设置了，则引发。  
  
   
  
## Examples  
 下面的示例创建三个听写语法，将它们添加到新的 <xref:System.Speech.Recognition.SpeechRecognitionEngine> 对象中，并返回新的对象。 第一个语法是默认的听写语法。 第二个语法是拼写听写语法。 第三个语法是包含上下文短语的默认听写语法。 <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A>方法用于在将上下文短语加载到对象后，将其与听写语法相关联 <xref:System.Speech.Recognition.SpeechRecognitionEngine> 。  
  
```csharp  
  
private SpeechRecognitionEngine LoadDictationGrammars()  
{  
  
  // Create a default dictation grammar.  
  DictationGrammar defaultDictationGrammar = new DictationGrammar();  
  defaultDictationGrammar.Name = "default dictation";  
  defaultDictationGrammar.Enabled = true;  
  
  // Create the spelling dictation grammar.  
  DictationGrammar spellingDictationGrammar =  
    new DictationGrammar("grammar:dictation#spelling");  
  spellingDictationGrammar.Name = "spelling dictation";  
  spellingDictationGrammar.Enabled = true;  
  
  // Create the question dictation grammar.  
  DictationGrammar customDictationGrammar =  
    new DictationGrammar("grammar:dictation");  
  customDictationGrammar.Name = "question dictation";  
  customDictationGrammar.Enabled = true;  
  
  // Create a SpeechRecognitionEngine object and add the grammars to it.  
  SpeechRecognitionEngine recoEngine = new SpeechRecognitionEngine();  
  recoEngine.LoadGrammar(defaultDictationGrammar);  
  recoEngine.LoadGrammar(spellingDictationGrammar);  
  recoEngine.LoadGrammar(customDictationGrammar);  
  
  // Add a context to customDictationGrammar.  
  customDictationGrammar.SetDictationContext("How do you", null);  
  
  return recoEngine;  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.Grammar" />
  </Docs>
  <Members>
    <MemberGroup MemberName=".ctor">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>初始化 <see cref="T:System.Speech.Recognition.DictationGrammar" /> 类的新实例。</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public DictationGrammar ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; DictationGrammar();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>初始化 <see cref="T:System.Speech.Recognition.DictationGrammar" /> 类的新实例用于 Windows 桌面语音技术提供的默认命令语法。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 默认的听写语法模拟标准听写实践，包括标点符号。 它不支持单词的拼写。  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public DictationGrammar (string topic);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string topic) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.#ctor(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (topic As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; DictationGrammar(System::String ^ topic);" />
      <MemberSignature Language="F#" Value="new System.Speech.Recognition.DictationGrammar : string -&gt; System.Speech.Recognition.DictationGrammar" Usage="new System.Speech.Recognition.DictationGrammar topic" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="topic" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="topic">一个符合 XML 的统一资源标识符 (URI)，指定听写语法（<c>grammar:dictation</c> 或 <c>grammar:dictation#spelling</c>）。</param>
        <summary>用特定的口述语法初始化 <see cref="T:System.Speech.Recognition.DictationGrammar" /> 类的新实例。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 语音平台使用专用 URI 语法来定义自定义听写语法。 值 `grammar:dictation` 指示默认的听写语法。 值 `grammar:dictation#spelling` 指示拼写听写语法。  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="SetDictationContext">
      <MemberSignature Language="C#" Value="public void SetDictationContext (string precedingText, string subsequentText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetDictationContext(string precedingText, string subsequentText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetDictationContext (precedingText As String, subsequentText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetDictationContext(System::String ^ precedingText, System::String ^ subsequentText);" />
      <MemberSignature Language="F#" Value="member this.SetDictationContext : string * string -&gt; unit" Usage="dictationGrammar.SetDictationContext (precedingText, subsequentText)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="precedingText" Type="System.String" />
        <Parameter Name="subsequentText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="precedingText">文本指示口述上下文的开端。</param>
        <param name="subsequentText">文本指示口述上下文的末尾。</param>
        <summary>添加上下文到由 <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> 或 <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> 对象加载的听写语法。</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 默认情况下，听写语法不会使用特定的单词或字顺序来识别和解释音频输入。 向听写语法添加上下文时，识别引擎将使用 `precedingText` 和 `subsequentText` 来确定何时将语音解释为听写。  
  
> [!NOTE]
>  听写语法必须由 <xref:System.Speech.Recognition.SpeechRecognizer> 或 <xref:System.Speech.Recognition.SpeechRecognitionEngine> 对象加载，然后才能使用 <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> 来添加上下文。  
  
 下表描述了识别引擎如何使用这两个参数来确定何时使用听写语法。  
  
|`precedingText`|`subsequentText`|描述|  
|---------------------|----------------------|-----------------|  
|非 `null`|非 `null`|识别引擎使用这些条款来括上可能的候选短语。|  
|`null`|非 `null`|识别引擎使用 `subsequentText` 完成听写。|  
|非 `null`|`null`|识别引擎使用 `precedingText` 启动听写。|  
|`null`|`null`|使用听写语法时，识别引擎不使用上下文。|  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
      </Docs>
    </Member>
  </Members>
</Type>
